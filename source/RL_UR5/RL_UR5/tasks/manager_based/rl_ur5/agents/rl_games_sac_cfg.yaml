params:  
  seed: 42
  # environment wrapper clipping
  env:
    clip_observations: 100.0
    clip_actions: 5.0  
  algo:
    name: sac
  model:
    name: soft_actor_critic
  network:
    name: soft_actor_critic
    separate: True
    space:
      continuous:
        mu_activation: None
        sigma_activation: None
        mu_init:
          name: default
        sigma_init:
          name: const_initializer
          val: -1.0
    mlp:
      units: [256, 256, 128, 64]  # Adjusted network architecture for our task
      activation: elu  # Using elu as in our previous config
      initializer:
        name: default
    log_std_bounds: [-5, 2]  # Bounds for the log standard deviation
    inputs:
      observation_dict: True  # This tells the network to expect dictionary observations
  config:
    name: pose_tracking_ur5_sac
    env_name: rlgpu
    device: 'cuda:0'
    device_name: 'cuda:0'
    normalize_input: True
    normalize_value: True
    value_bootstrap: True
    reward_shaper:
      scale_value: 1.0
    max_epochs: 1200
    num_steps_per_episode: 16  # Steps per episode
    save_best_after: 200
    save_frequency: 100
    gamma: 0.99
    init_alpha: 1.0  # Initial temperature parameter
    alpha_lr: 0.0002  # Learning rate for temperature parameter
    actor_lr: 0.0003  # Actor learning rate
    critic_lr: 0.0003  # Critic learning rate
    critic_tau: 0.005  # Soft update coefficient for critic
    batch_size: 1024  # Batch size for updates
    learnable_temperature: True  # Whether to learn the temperature parameter
    num_warmup_steps: 5  # Warmup steps multiplier
    replay_buffer_size: 1000000  # Size of replay buffer
    num_actors: 8  # Match our environment's num_envs
    env_config:
      env_name: pose_tracking_ur5